\documentclass{article}

% Packages
\usepackage{graphicx} % For including figures
\usepackage{amsmath} % For mathematical symbols and equations
\usepackage{hyperref} % For hyperlinks
\usepackage{listings} % For including code snippets
\usepackage{float} % For precise figure placement using [H]

% Title
\title{Adversarial Robustness}
\author{Ekaterina Mozhegova}
\date{7th April}

% Begin Document
\begin{document}

\maketitle

% Abstract
The study is based on the tutorial "Adversarial Robustness - Theory and Practice".

\begin{abstract}
  % Adversarial attacks are small but malicious pertrubations over the input dataset. Often invisible to the human eye, they harshly damage the model's accuracy. These adversarial attacks present a threat to security-critical tasks, 
  % such as computer vision, natural language processing, and other. For example, in cybersecurity and healthcare domains.


  Adversarial attacks are small yet malicious perturbations applied to input datasets. Often invisible to the human eye, they can damage the internal structure of the model and 
  consequently its accuracy and reliability. These attacks pose a threat to security-critical tasks, including computer vision and natural language processing, among others.
  So, the task of a new field of adversarial robustness is to ensure the models are robust to such perturbations. Zico Kolter and Aleksander Madry observe several types of adversarial attakcs and 
  propose methods for handling these attacks.
  
\end{abstract}

% Table of Contents
\tableofcontents
\newpage

% Include Chapters
\input{report1.tex}
\input{report2.tex}
\input{report3.tex}
\end{document}
