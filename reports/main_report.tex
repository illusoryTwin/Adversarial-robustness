\documentclass{article}

% Packages
\usepackage{graphicx} % For including figures
\usepackage{amsmath} % For mathematical symbols and equations
\usepackage{hyperref} % For hyperlinks
\usepackage{listings} % For including code snippets
\usepackage{float} % For precise figure placement using [H]

% Title
\title{Adversarial Robustness}
\author{Ekaterina Mozhegova}
\date{7th April}

% Begin Document
\begin{document}

\maketitle

% Abstract
The study is based on the tutorial "Adversarial Robustness - Theory and Practice".

\begin{abstract}
  % Adversarial attacks are small but malicious pertrubations over the input dataset. Often invisible to the human eye, they harshly damage the model's accuracy. These adversarial attacks present a threat to security-critical tasks, 
  % such as computer vision, natural language processing, and other. For example, in cybersecurity and healthcare domains.


  Adversarial attacks are small yet malicious perturbations applied to input datasets. Often invisible to the human eye, they can damage the internal structure of the model and 
  consequently its accuracy and reliability. These attacks pose a threat to security-critical tasks, including computer vision and natural language processing, among others.
  Therefore, the objective of the new field of study is to ensure that models remain resilient to such perturbations.  
  Zico Kolter and Aleksander Madry have observed several types of adversarial attacks and proposed methods for building robust models. They are all covered in this study. 
  
\end{abstract}

% Table of Contents
\tableofcontents
\newpage

% Include Chapters
\input{report1.tex}
\input{report2.tex}
\input{report3.tex}
\input{report4.tex}
\end{document}
